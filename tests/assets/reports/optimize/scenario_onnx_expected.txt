Optimization started.
Model: Collecting model information ...
Model: Collecting model information OK
Model: Finding max batch size for fixed shapes based pipelines ...
Model: Finding max batch size for fixed shapes based pipelines OK
Model: Building TensorRT engine trt-fp32 from ONNX model ...
Model: Building TensorRT engine trt-fp32 from ONNX model OK
Model: Building TensorRT engine trt-fp16 from ONNX model ...
Model: Building TensorRT engine trt-fp16 from ONNX model OK
Model: Validating model onnx on OnnxCUDA backend ...
Model: Validating model onnx on OnnxCUDA backend OK
Model: Validating model onnx on OnnxTensorRT backend ...
Model: Validating model onnx on OnnxTensorRT backend OK
Model: Validating model trt-fp32 on TensorRT backend ...
Model: Validating model trt-fp32 on TensorRT backend OK
Model: Validating model trt-fp16 on TensorRT backend ...
Model: Validating model trt-fp16 on TensorRT backend OK
Model: Benchmarking model onnx on OnnxCUDA backend ...
Model: Benchmarking model onnx on OnnxCUDA backend OK
Model: Benchmarking model onnx on OnnxTensorRT backend ...
Model: Benchmarking model onnx on OnnxTensorRT backend OK
Model: Benchmarking model trt-fp32 on TensorRT backend ...
Model: Benchmarking model trt-fp32 on TensorRT backend OK
Model: Benchmarking model trt-fp16 on TensorRT backend ...
Model: Benchmarking model trt-fp16 on TensorRT backend OK
Model: Verifying model onnx on OnnxCUDA backend ...
Model: Verifying model onnx on OnnxCUDA backend OK
Model: Verifying model onnx on OnnxTensorRT backend ...
Model: Verifying model onnx on OnnxTensorRT backend OK
Model: Verifying model trt-fp32 on TensorRT backend ...
Model: Verifying model trt-fp32 on TensorRT backend OK
Model: Verifying model trt-fp16 on TensorRT backend ...
Model: Verifying model trt-fp16 on TensorRT backend OK
Optimization finished for the model.
   Optimization result for max throughput and min latency strategy   
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Optimized backend            ┃ Path                               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ trt-fp16 on TensorRT backend │ onnx_workspace/trt-fp16/model.plan │
└──────────────────────────────┴────────────────────────────────────┘
